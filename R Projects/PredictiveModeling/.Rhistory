}
####################
##  Create basic model
####################
create_model <- function(trainData, target) {
set.seed(120)
myglm <- glm(target ~ . , data = trainData, family = "binomial")
return(myglm)
}
###############################################
install.packages('caret')
library(caret)
createDataPartition(y = red_wine_data$quality,times = 1,p = 0.66)
train_idx <- createDataPartition(y = red_wine_data$quality,times = 1,p = 0.66)
train_idx
length(train_idx)
as.vector(train_idx)
length(as.vector(train_idx))
train_idx <- createDataPartition(y = red_wine_data$quality,times = 1,p = 0.66,list = F)
for(c in colnames(red_wine_data)){
idx <- flag_missing_val(red_wine_data,c)
red_wine_data <- impute_vars(red_wine_data,c,idx)
}
for(c in colnames(red_wine_data)){
idx <- flag_missing_val(red_wine_data,c)
if(length(idx) != 0){
red_wine_data <- impute_vars(red_wine_data,c,idx)
}
}
model <- create_model(red_wine_data[train_idx,],red_wine_data$quality)
model <- create_model(red_wine_data[train_idx,],red_wine_data$quality[train_idx])
create_model <- function(trainData, target) {
set.seed(120)
model <- lm(target ~ . , data = trainData, family = "binomial")
return(model)
}
model <- create_model(red_wine_data[train_idx,],red_wine_data$quality[train_idx])
create_model <- function(trainData, target) {
set.seed(120)
model <- lm(target ~ . , data = trainData)
return(model)
}
model <- create_model(red_wine_data[train_idx,],red_wine_data$quality[train_idx])
score <- predict.lm(model,newdata = red_wine_data[-train_idx,])
auc(red_wine_data$quality[-train_idx],score)
?auc
install.packages('pROC')
library(pROC)
auc(red_wine_data$quality[-train_idx],score)
red_wine_data$quality[-train_idx]
score
white_wine_data <-
read.csv(
'data/winequality-white.csv',
check.names = F,
sep = ';',
stringsAsFactors = T
)
train_idx <- createDataPartition(y = white_wine_data$quality,times = 1,p = 0.66,list = F)
model <- create_model(white_wine_data[train_idx,],white_wine_data$quality[train_idx])
score <- predict.lm(model,newdata = white_wine_data[-train_idx,])
auc(white_wine_data$quality[-train_idx],score)
forest_fire_data <- read.csv('data/forestfires.csv')
forest_fire_data$logArea <- log(forest_fire_data$area)
View(forest_fire_data)
forest_fire_data$logArea <- log2(forest_fire_data$area)
View(forest_fire_data)
forest_fire_data$logArea <- log10(forest_fire_data$area)
library(dplyr)
install.packages('dplyr')
forest_fire_data <- read.csv('data/forestfires.csv')
library(dplyr)
install.packages("dplyr")
forest_fire_data <- read.csv('data/forestfires.csv')
forest_fire_data$logArea <- log(forest_fire_data$area+1)
library(dplyr)
colnames(forest_fire_data)
lin_model <- lm(logArea ~ .,forest_fire_data)
summary(lin_model)
lin_model <- lm(logArea ~ .,forest_fire_data[,-c('Area')])
lin_model <- lm(logArea ~ .,forest_fire_data[-c('Area')])
lin_model <- lm(logArea ~ .,forest_fire_data[-13])
summary(lin_model)
features <- c('temp','RH','wind','rain')
install.packages("e1071")
library(e1071)
library(caret)
?createFolds
train_idx <- createFolds(forest_fire_data$logArea,10)
train_idx
train_idx$Fold01
train_idx[1]
train_idx[[1]]
length(train_idx)
for(i in 1:10){ print(length(train_idx[[i]]))}
train_idx <- createDataPartition(forest_fire_data$logArea, p = c(0.67,0.33))
train_idx$Resample1
length(train_idx[[1]])
348/517
?trainControl
?svm
as.data.matrix(forest_fire_data[train_idx,features])
z <- as.data.frame.matrix(forest_fire_data[train_idx,features])
z <- as.data.frame.matrix(forest_fire_data[train_idx[[1]],features])
z <- data.matrix(forest_fire_data[train_idx[[1]],features])
?predict
library(e1071)
for (run in 1:30) {
train_idx <- createDataPartition(forest_fire_data$logArea, p = c(0.67,0.33))
svr_model <- svm(data.matrix(forest_fire_data[train_idx,features]),forest_fire_data$logArea,type = 'eps-regression',kernel = 'rbf',cross = 10)
predictions <- predict(svr_model,newdata = forest_fire_data[-train_idx,features])
accuracy <- predictions - forest_fire_data[-train_idx,'logArea']
print(accuracy)
}
for (run in 1:30) {
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea,
type = 'eps-regression',
kernel = 'rbf',
cross = 10
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
accuracy <- predictions - forest_fire_data[-train_idx[[1]], 'logArea']
print(accuracy)
}
for (run in 1:30) {
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea,
type = 'eps-regression',
kernel = 'radial basis',
cross = 10
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
accuracy <- predictions - forest_fire_data[-train_idx[[1]], 'logArea']
print(accuracy)
}
?svm
for (run in 1:30) {
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea,
type = 'eps-regression',
kernel = 'radial',
cross = 10
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
accuracy <- predictions - forest_fire_data[-train_idx[[1]], 'logArea']
print(accuracy)
}
for (run in 1:30) {
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea[train_idx[[1]]],
type = 'eps-regression',
kernel = 'radial',
cross = 10
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
accuracy <- predictions - forest_fire_data[-train_idx[[1]], 'logArea']
print(accuracy)
}
?ifelse
for (run in 1:30) {
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea[train_idx[[1]]],
type = 'eps-regression',
kernel = 'radial',
cross = 10
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
accuracy <- ifelse(predictions - forest_fire_data$logArea[-train_idx[[1]]] < 0.1,1,0)
print(accuracy)
}
for (run in 1:30) {
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea[train_idx[[1]]],
type = 'eps-regression',
kernel = 'radial',
cross = 10
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
score <- ifelse(predictions - forest_fire_data$logArea[-train_idx[[1]]] < 0.1,1,0)
accuracy <- sum(score)/length(score)
print(accuracy)
}
cost_var <- c(0.1:1)
cost_var <- 0.1:1
C(0.1:1)
cost_var <- seq(0.1,1,0.1)
cost_var <- seq(0.1,1,0.1);eps_var <- seq(0.01,099,0.3)
for (run in 1:30) {
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
cost_var <- seq(0.1, 1, 0.1)
eps_var <- seq(0.01, 099, 0.3)
accuracy <- 0
optimal_eps <- 0
optimal_cost <- 0
for (c in cost_var{
for (e in eps_var) {
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea[train_idx[[1]]],
type = 'eps-regression',
kernel = 'radial',
cross = 10,
cost = c,
epsilon = e
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
score <-
ifelse(predictions - forest_fire_data$logArea[-train_idx[[1]]] < 0.1, 1, 0)
tmp_accuracy <- sum(score) / length(score)
if(tmp_accuracy > accuracy){
accuracy <- tmp_accuracy
optimal_eps <- e
optimal_cost <- c
}
}
})
print(paste0(accuracy,':: cost = ',c,' :: epsilon = ',e))
}
for (run in 1:30) {
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
cost_var <- seq(0.1, 1, 0.1)
eps_var <- seq(0.01, 099, 0.3)
accuracy <- 0
optimal_eps <- 0
optimal_cost <- 0
for (c in cost_var) {
for (e in eps_var) {
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea[train_idx[[1]]],
type = 'eps-regression',
kernel = 'radial',
cross = 10,
cost = c,
epsilon = e
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
score <-
ifelse(predictions - forest_fire_data$logArea[-train_idx[[1]]] < 0.1, 1, 0)
tmp_accuracy <- sum(score) / length(score)
if (tmp_accuracy > accuracy) {
accuracy <- tmp_accuracy
optimal_eps <- e
optimal_cost <- c
}
}
}
print(paste0(accuracy, ':: cost = ', c, ' :: epsilon = ', e))
}
#### Ensemble learning & Boosting techniques
forest_fire_data <- read.csv('data/forestfires.csv')
forest_fire_data$logArea <- log(forest_fire_data$area + 1)
library(dplyr)
##################
##  Feature selection - Pending
# lin_model <- lm(logArea ~ .,forest_fire_data[-13])
# summary(lin_model)
colnames(forest_fire_data)
features <- c('temp', 'RH', 'wind', 'rain')
##################
library(e1071)
library(caret)
for (run in 1:30) {
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
cost_var <- seq(0.1, 1, 0.1)
eps_var <- seq(0.01, 099, 0.3)
accuracy <- 0
optimal_eps <- 0
optimal_cost <- 0
for (c in cost_var) {
for (e in eps_var) {
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea[train_idx[[1]]],
type = 'eps-regression',
kernel = 'radial',
cross = 10,
cost = c,
epsilon = e
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
score <-
ifelse(predictions - forest_fire_data$logArea[-train_idx[[1]]] < 0.1, 1, 0)
tmp_accuracy <- sum(score) / length(score)
if (tmp_accuracy > accuracy) {
accuracy <- tmp_accuracy
optimal_eps <- e
optimal_cost <- c
}
}
}
print(paste0(accuracy, ':: cost = ', c, ' :: epsilon = ', e))
}
for (run in 1:30) {
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
cost_var <- seq(0.1, 1, 0.1)
eps_var <- seq(0.01, 099, 0.3)
accuracy <- 0
optimal_eps <- 0
optimal_cost <- 0
for (c in cost_var) {
print(e)
for (e in eps_var) {
print(e)
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea[train_idx[[1]]],
type = 'eps-regression',
kernel = 'radial',
cross = 10,
cost = c,
epsilon = e
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
score <-
ifelse(predictions - forest_fire_data$logArea[-train_idx[[1]]] < 0.1, 1, 0)
tmp_accuracy <- sum(score) / length(score)
if (tmp_accuracy > accuracy) {
accuracy <- tmp_accuracy
optimal_eps <- e
optimal_cost <- c
}
}
}
print(paste0(accuracy, ':: cost = ', c, ' :: epsilon = ', e))
}
for (run in 1:30) {
print(paste0('------------',run,'------------'))
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
cost_var <- seq(0.1, 1, 0.1)
eps_var <- seq(0.01, 099, 0.3)
accuracy <- 0
optimal_eps <- 0
optimal_cost <- 0
for (c in cost_var) {
print(c)
for (e in eps_var) {
print(e)
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea[train_idx[[1]]],
type = 'eps-regression',
kernel = 'radial',
cross = 10,
cost = c,
epsilon = e
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
score <-
ifelse(predictions - forest_fire_data$logArea[-train_idx[[1]]] < 0.1, 1, 0)
tmp_accuracy <- sum(score) / length(score)
if (tmp_accuracy > accuracy) {
accuracy <- tmp_accuracy
optimal_eps <- e
optimal_cost <- c
}
}
}
print(paste0(accuracy, ':: cost = ', c, ' :: epsilon = ', e))
}
for (run in 1:30) {
print(paste0('------------',run,'------------'))
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
cost_var <- seq(0.1, 1, 0.1)
eps_var <- seq(0.01, 0.99, 0.03)
accuracy <- 0
optimal_eps <- 0
optimal_cost <- 0
for (c in cost_var) {
print(c)
for (e in eps_var) {
print(e)
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea[train_idx[[1]]],
type = 'eps-regression',
kernel = 'radial',
cross = 10,
cost = c,
epsilon = e
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
score <-
ifelse(predictions - forest_fire_data$logArea[-train_idx[[1]]] < 0.1, 1, 0)
tmp_accuracy <- sum(score) / length(score)
if (tmp_accuracy > accuracy) {
accuracy <- tmp_accuracy
optimal_eps <- e
optimal_cost <- c
}
}
}
print(paste0(accuracy, ':: cost = ', c, ' :: epsilon = ', e))
}
#### Ensemble learning & Boosting techniques
forest_fire_data <- read.csv('data/forestfires.csv')
forest_fire_data$logArea <- log(forest_fire_data$area + 1)
library(dplyr)
##################
##  Feature selection - Pending
# lin_model <- lm(logArea ~ .,forest_fire_data[-13])
# summary(lin_model)
colnames(forest_fire_data)
features <- c('temp', 'RH', 'wind', 'rain')
##################
library(e1071)
library(caret)
for (run in 1:30) {
print(paste0('------------',run,'------------'))
train_idx <-
createDataPartition(forest_fire_data$logArea, p = c(0.67, 0.33))
cost_var <- seq(0.1, 1, 0.1)
eps_var <- seq(0.01, 0.99, 0.03)
accuracy <- 0
optimal_eps <- 0
optimal_cost <- 0
for (c in cost_var) {
# print(c)
for (e in eps_var) {
# print(e)
svr_model <-
svm(
data.matrix(forest_fire_data[train_idx[[1]], features]),
forest_fire_data$logArea[train_idx[[1]]],
type = 'eps-regression',
kernel = 'radial',
cross = 10,
cost = c,
epsilon = e
)
predictions <-
predict(svr_model, newdata = forest_fire_data[-train_idx[[1]], features])
score <-
ifelse(predictions - forest_fire_data$logArea[-train_idx[[1]]] < 0.1, 1, 0)
tmp_accuracy <- sum(score) / length(score)
if (tmp_accuracy > accuracy) {
accuracy <- tmp_accuracy
optimal_eps <- e
optimal_cost <- c
}
}
}
print(paste0("Accuracy: ",accuracy, ':: cost = ', c, ' :: epsilon = ', e))
}
custdata <- read.table('../../Resources/Datasets/101s/Custdata.tsv',sep = '\t',header = T)
View(custdata)
summary(custdata)
library(ggplot2)
install.packages('ggplot2')
colnames(custdata)
str(custdata$health.ins)
library(ggplot2)
colnames(custdata)
summary(custdata$health.ins)
summary(custdata$age)
ggplot(custdata,aes(age,health.ins))+
geom_point()
with(custdata,table(sex,health.ins))
with(custdata,table(is.employed,health.ins))
with(custdata,table(income,health.ins))
with(custdata,table(state.of.res,health.ins))
View(custdata)
View(custdata)
